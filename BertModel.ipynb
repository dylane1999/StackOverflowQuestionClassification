{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Preliminaries\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.10\n",
    "train_valid_ratio = 0.80\n",
    "\n",
    "first_n_words = 350\n",
    "\n",
    "destination_folder = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preproccess the raw data into title text combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"./data/raw_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_string(x):\n",
    "    x = x.split(maxsplit=first_n_words)\n",
    "    x = ' '.join(x[:first_n_words])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df_raw.loc[0:100000]\n",
    "df_short[df_short[\"OpenStatus\"] != \"open\"]\n",
    "\n",
    "\n",
    "#does the tite match the question\n",
    "# using open status to give reccomendations to a person \n",
    "# generate a better title based on the body markdwn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_short['label'] = (df_short['OpenStatus'] == 'open').astype('int')\n",
    "df_short['titletext'] = df_short['Title'] + \". \" + df_short['BodyMarkdown']\n",
    "\n",
    "# Trim text and titletext to first_n_words\n",
    "df_short['BodyMarkdown'] = df_short['BodyMarkdown'].apply(trim_string)\n",
    "df_short['titletext'] = df_short['titletext'].apply(trim_string) \n",
    "\n",
    "\n",
    "# Split according to label\n",
    "df_open = df_short[df_short['label'] == 1]\n",
    "df_closed = df_short[df_short['label'] == 0]\n",
    "# Train-test split\n",
    "df_open_full_train, df_open_test = train_test_split(df_open, train_size = train_test_ratio, random_state = 1)\n",
    "df_closed_full_train, df_closed_test = train_test_split(df_closed, train_size = train_test_ratio, random_state = 1)\n",
    "\n",
    "# Train-valid split\n",
    "df_open_train, df_open_valid = train_test_split(df_open_full_train, train_size = train_valid_ratio, random_state = 1)\n",
    "df_closed_train, df_closed_valid = train_test_split(df_closed_full_train, train_size = train_valid_ratio, random_state = 1)\n",
    "\n",
    "# Concatenate splits of different labels\n",
    "df_train = pd.concat([df_open_train, df_closed_train], ignore_index=True, sort=False)\n",
    "df_valid = pd.concat([df_open_valid, df_closed_valid], ignore_index=True, sort=False)\n",
    "df_test = pd.concat([df_open_test, df_closed_test], ignore_index=True, sort=False)\n",
    "\n",
    "# Write preprocessed data\n",
    "df_train.to_csv(\"./data\" + '/train.csv', index=False)\n",
    "df_valid.to_csv(destination_folder + '/valid.csv', index=False)\n",
    "df_test.to_csv(destination_folder + '/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Model parameter\n",
    "MAX_SEQ_LEN = 500\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "fields = [('label', label_field), ('title', text_field), ('text', text_field), ('titletext', text_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=\"./data\", train='train.csv', validation='valid.csv',\n",
    "                                           test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.text), train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                             train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=16, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions\n",
    "\n",
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):\n",
    "    \n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (labels, title, text, titletext), _ in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)           \n",
    "            labels = labels.to(device)\n",
    "            titletext = titletext.type(torch.LongTensor)  \n",
    "            titletext = titletext.to(device)\n",
    "            output = model(titletext, labels)\n",
    "            loss, _ = output\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "\n",
    "                    # validation loop\n",
    "                    for (labels, title, text, titletext), _ in valid_loader:\n",
    "                        labels = labels.type(torch.LongTensor)           \n",
    "                        labels = labels.to(device)\n",
    "                        titletext = titletext.type(torch.LongTensor)  \n",
    "                        titletext = titletext.to(device)\n",
    "                        output = model(titletext, labels)\n",
    "                        loss, _ = output\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
    "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "model = BERT()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "train(model=model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "\n",
    "word embeddings + LSTM https://towardsdatascience.com/text-classification-on-disaster-tweets-with-lstm-and-word-embedding-df35f039c1db\n",
    "\n",
    "https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare columns\n",
    "# df_raw['label'] = (df_raw['OpenStatus'] == 'open').astype('int')\n",
    "# df_raw['titletext'] = df_raw['Title'] + \". \" + df_raw['BodyMarkdown']\n",
    "# # df_raw = df_raw.reindex(columns=['label', 'Title', 'BodyMarkdown', 'titletext'])\n",
    "\n",
    "# # # Drop rows with empty text\n",
    "# # df_raw.drop( df_raw[df_raw.text.str.len() < 5].index, inplace=True)\n",
    "\n",
    "# # Trim text and titletext to first_n_words\n",
    "# df_raw['BodyMarkdown'] = df_raw['BodyMarkdown'].apply(trim_string)\n",
    "# df_raw['titletext'] = df_raw['titletext'].apply(trim_string) \n",
    "\n",
    "# # Split according to label\n",
    "# df_open = df_raw[df_raw['label'] == 1]\n",
    "# df_closed = df_raw[df_raw['label'] == 0]\n",
    "\n",
    "# # Train-test split\n",
    "# df_open_full_train, df_open_test = train_test_split(df_open, train_size = train_test_ratio, random_state = 1)\n",
    "# df_closed_full_train, df_closed_test = train_test_split(df_closed, train_size = train_test_ratio, random_state = 1)\n",
    "\n",
    "# # Train-valid split\n",
    "# df_open_train, df_open_valid = train_test_split(df_open_full_train, train_size = train_valid_ratio, random_state = 1)\n",
    "# df_closed_train, df_closed_valid = train_test_split(df_closed_full_train, train_size = train_valid_ratio, random_state = 1)\n",
    "\n",
    "# # Concatenate splits of different labels\n",
    "# df_train = pd.concat([df_open_train, df_closed_train], ignore_index=True, sort=False)\n",
    "# df_valid = pd.concat([df_open_valid, df_closed_valid], ignore_index=True, sort=False)\n",
    "# df_test = pd.concat([df_open_test, df_closed_test], ignore_index=True, sort=False)\n",
    "\n",
    "# # Write preprocessed data\n",
    "# df_train.to_csv(\"./data\" + '/train.csv', index=False)\n",
    "# df_valid.to_csv(destination_folder + '/valid.csv', index=False)\n",
    "# df_test.to_csv(destination_folder + '/test.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2972d6e7ffecf54ed5e842bd2e14961f37161ce7e144cb9624e826c965cf2420"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
