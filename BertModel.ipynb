{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy\n",
    "# Models\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Training\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# import seaborn as sns\n",
    "\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preproccess the raw data into title text combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset('csv', data_files={ \"train\": 'data/train.csv', \"test\": 'data/test.csv', \"valid\": 'data/valid.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"titletext\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw_datasets = raw_datasets.map(lambda batch: { \"binary_labels\": tensorflow.keras.utils.to_categorical(batch[\"labels\"],2) }, batched=True) \n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(250))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(250))\n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = small_train_dataset.remove_columns([\"titletext\"]).with_format(\"tensorflow\")\n",
    "tf_eval_dataset = small_eval_dataset.remove_columns([\"titletext\"]).with_format(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
    "train_tf_dataset = tensorflow.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"labels\"]))\n",
    "train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(8)\n",
    "\n",
    "eval_features = {x: tf_eval_dataset[x] for x in tokenizer.model_input_names}\n",
    "eval_tf_dataset = tensorflow.data.Dataset.from_tensor_slices((eval_features, tf_eval_dataset[\"labels\"]))\n",
    "eval_tf_dataset = eval_tf_dataset.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tensorflow.keras.metrics.SparseCategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "model.fit(train_tf_dataset, validation_data=eval_tf_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "\n",
    "word embeddings + LSTM https://towardsdatascience.com/text-classification-on-disaster-tweets-with-lstm-and-word-embedding-df35f039c1db\n",
    "\n",
    "https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data\n",
    "\n",
    "https://huggingface.co/transformers/training.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare columns\n",
    "# df_raw['label'] = (df_raw['OpenStatus'] == 'open').astype('int')\n",
    "# df_raw['titletext'] = df_raw['Title'] + \". \" + df_raw['BodyMarkdown']\n",
    "# # df_raw = df_raw.reindex(columns=['label', 'Title', 'BodyMarkdown', 'titletext'])\n",
    "\n",
    "# # # Drop rows with empty text\n",
    "# # df_raw.drop( df_raw[df_raw.text.str.len() < 5].index, inplace=True)\n",
    "\n",
    "# # Trim text and titletext to first_n_words\n",
    "# df_raw['BodyMarkdown'] = df_raw['BodyMarkdown'].apply(trim_string)\n",
    "# df_raw['titletext'] = df_raw['titletext'].apply(trim_string) \n",
    "\n",
    "# # Split according to label\n",
    "# df_open = df_raw[df_raw['label'] == 1]\n",
    "# df_closed = df_raw[df_raw['label'] == 0]\n",
    "\n",
    "# # Train-test split\n",
    "# df_open_full_train, df_open_test = train_test_split(df_open, train_size = train_test_ratio, random_state = 1)\n",
    "# df_closed_full_train, df_closed_test = train_test_split(df_closed, train_size = train_test_ratio, random_state = 1)\n",
    "\n",
    "# # Train-valid split\n",
    "# df_open_train, df_open_valid = train_test_split(df_open_full_train, train_size = train_valid_ratio, random_state = 1)\n",
    "# df_closed_train, df_closed_valid = train_test_split(df_closed_full_train, train_size = train_valid_ratio, random_state = 1)\n",
    "\n",
    "# # Concatenate splits of different labels\n",
    "# df_train = pd.concat([df_open_train, df_closed_train], ignore_index=True, sort=False)\n",
    "# df_valid = pd.concat([df_open_valid, df_closed_valid], ignore_index=True, sort=False)\n",
    "# df_test = pd.concat([df_open_test, df_closed_test], ignore_index=True, sort=False)\n",
    "\n",
    "# # Write preprocessed data\n",
    "# df_train.to_csv(\"./data\" + '/train.csv', index=False)\n",
    "# df_valid.to_csv(destination_folder + '/valid.csv', index=False)\n",
    "# df_test.to_csv(destination_folder + '/test.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2972d6e7ffecf54ed5e842bd2e14961f37161ce7e144cb9624e826c965cf2420"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
